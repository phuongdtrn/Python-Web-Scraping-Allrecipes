{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk import flatten\n",
    "import s3fs\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty lists to store data of each attribute\n",
    "title_list = []\n",
    "description_list = []\n",
    "star_list = []\n",
    "rating_list = []\n",
    "review_list = []\n",
    "photo_list = []\n",
    "num_ingredient_list = []\n",
    "ingredient_list = []\n",
    "total_time_list = []\n",
    "prep_time_list = []\n",
    "cook_time_list = []\n",
    "additional_time_list = []\n",
    "serving_list = []\n",
    "protein_list  = []\n",
    "carb_list = []\n",
    "fat_list = []\n",
    "cholesterol_list = []\n",
    "sodium_list = []\n",
    "calorie_list = []\n",
    "recipe_id_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20626,30000): #input any range of recipe URL, recipes are spaced far\n",
    "    try:\n",
    "        #getting all attributes\n",
    "        r = urllib.request.urlopen(\"http://allrecipes.com/recipe/\" + str(i))\n",
    "        soup = BeautifulSoup(r, 'html.parser')\n",
    "        \n",
    "        name = soup.find('h1', class_ ='headline heading-content elementFont__display').getText()\n",
    "        description = soup.find('p', class_ ='margin-0-auto').getText()\n",
    "        star = soup.find('span', class_ ='review-star-text visually-hidden').getText()\n",
    "        \n",
    "        no_rating_no_reviews = soup.find('a', class_ ='ugc-ratings-link elementFont__detailsLink--underlined no-ratings')\n",
    "        rating_exists = soup.find('span', class_ ='ugc-ratings-item elementFont__details')\n",
    "        review = soup.find('a', class_ ='ugc-ratings-link elementFont__detailsLink--underlined ugc-reviews-link')\n",
    "        \n",
    "        photo = soup.find('a', class_ ='ugc-ratings-link elementFont__detailsLink--underlined ugc-photos-link')\n",
    "        p_tags = soup.find_all('span', class_ ='ingredients-item-name elementFont__body')\n",
    "        \n",
    "        ingredients = []\n",
    "        for each in p_tags:\n",
    "            ingredients.append(str(each.getText()))\n",
    "        \n",
    "        cook_time_attributes = soup.find_all('div', class_ ='recipe-meta-item-header elementFont__subtitle--bold elementFont__transformCapitalize')\n",
    "        attributes = []\n",
    "        for each in cook_time_attributes:\n",
    "            attributes.append(str(each.get_text()).lower())\n",
    "        cook_time_values = soup.find_all('div', class_ ='recipe-meta-item-body elementFont__subtitle')\n",
    "        \n",
    "        raw_nutrition = soup.find('div', class_ ='recipeNutritionSectionBlock').getText()\n",
    "        if ('Per Serving:' in raw_nutrition) and ('. Full Nutrition' in raw_nutrition):\n",
    "            raw_nutrition = raw_nutrition[15:-18].lower()\n",
    "            if 'calories' not in raw_nutrition:\n",
    "                raise ValueError\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        #Time variables\n",
    "        cook_values = []\n",
    "        for each in cook_time_values:\n",
    "            cook_values.append(str(each.get_text()).lower())\n",
    "        for a in range(len(cook_values)-1): #not converting yield bc excluding yield as attribute\n",
    "            cook_values[a] = cook_values[a].strip()\n",
    "            cook_values[a] = re.sub('[a-z]* weeks', '*24*60*7', cook_values[a])\n",
    "            cook_values[a] = re.sub('[a-z]* week', '*24*60*7', cook_values[a])\n",
    "            cook_values[a] = re.sub('[a-z]* days', '*24*60', cook_values[a])\n",
    "            cook_values[a] = re.sub('[a-z]* day', '*24*60', cook_values[a])\n",
    "            cook_values[a] = re.sub('[a-z]* hrs', '*60', cook_values[a])\n",
    "            cook_values[a] = re.sub('[a-z]* hr', '*60', cook_values[a])\n",
    "            cook_values[a] = re.sub('[a-z]* mins', '', cook_values[a])\n",
    "            cook_values[a] = re.sub('[a-z]* min', '', cook_values[a])\n",
    "            cook_values[a] = re.sub('[a-z]* ', '+', cook_values[a])\n",
    "            cook_values[a] = eval(cook_values[a])\n",
    "        additional_cook_info = dict(zip(attributes, cook_values))\n",
    "\n",
    "        #title\n",
    "        title_list.append(name)\n",
    "\n",
    "        #description\n",
    "        description_list.append(description)\n",
    "\n",
    "        #star\n",
    "        star = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", star)\n",
    "        if not star:\n",
    "            star = None\n",
    "        star_list.append(star)\n",
    "\n",
    "        #rating\n",
    "        if no_rating_no_reviews is not None and no_rating_no_reviews != []:\n",
    "            rating = None\n",
    "        elif rating_exists is not None and rating_exists != []:\n",
    "            rating = int(rating_exists.getText().strip().replace(\",\",\"\").split(' ')[0])\n",
    "        else:\n",
    "            rating = None\n",
    "        rating_list.append(rating)\n",
    "\n",
    "        #review\n",
    "        if review is None:\n",
    "            review = 0\n",
    "            review_list.append(review)\n",
    "        else:\n",
    "            review = soup.find('a', class_ ='ugc-ratings-link elementFont__detailsLink--underlined ugc-reviews-link').getText().strip()\n",
    "            review = int(review.replace(\",\",\"\").split(' ')[0])\n",
    "            review_list.append(review)\n",
    "\n",
    "        #photos\n",
    "        if photo:\n",
    "            photo = int(photo.getText().strip().replace(\",\",\"\").split(' ')[0])\n",
    "            #photo = list(map(int, re.findall('\\d+', photo)))\n",
    "        elif not photo:\n",
    "            photo = 0\n",
    "        photo_list.append(photo)\n",
    "\n",
    "        #ingredients\n",
    "        total_ingredients = len(ingredients)\n",
    "        ingredient_string = ','.join(ingredients)\n",
    "        num_ingredient_list.append(total_ingredients)\n",
    "        ingredient_list.append(ingredient_string)\n",
    "\n",
    "        #Total cooking time\n",
    "        total_time = additional_cook_info.get('total:', None)\n",
    "        total_time_list.append(total_time)\n",
    "\n",
    "        #Prepreation time\n",
    "        prep_time = additional_cook_info.get('prep:', None)\n",
    "        prep_time_list.append(prep_time)\n",
    "\n",
    "        #Cook time\n",
    "        cook_time = additional_cook_info.get('cook:', None)\n",
    "        cook_time_list.append(cook_time)\n",
    "\n",
    "        #Addtional cooking time\n",
    "        additional_time = additional_cook_info.get('additional:', None)\n",
    "        additional_time_list.append(additional_time)\n",
    "\n",
    "        #Servings per dish\n",
    "        servings = additional_cook_info.get('servings:', None)\n",
    "        serving_list.append(servings)\n",
    "\n",
    "        #Nutrition facts\n",
    "        nutrition = []\n",
    "        raw_nutrition = raw_nutrition.split(';')\n",
    "        for item in raw_nutrition:\n",
    "            item = item.strip().lower()\n",
    "            nutrition.append(item)\n",
    "        nutrition_dict = dict(j.split(' ') for j in nutrition)\n",
    "        calorie_key = ''\n",
    "        for k,v in nutrition_dict.items():\n",
    "            if v == 'calories':\n",
    "                calorie_key = k\n",
    "        nutrition_dict['calories'] = nutrition_dict.pop(calorie_key, None)\n",
    "        nutrition_dict['calories'] = calorie_key\n",
    "\n",
    "        #Protein (g)\n",
    "        protein = nutrition_dict.get('protein', None)\n",
    "        if protein is not None:\n",
    "            protein = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", protein)\n",
    "        protein_list.append(protein)\n",
    "\n",
    "        #Carbs (g)\n",
    "        carbohydrates = nutrition_dict.get('carbohydrates', None)\n",
    "        if carbohydrates is not None:\n",
    "            carbohydrates = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", carbohydrates)\n",
    "        carb_list.append(carbohydrates)\n",
    "\n",
    "        #Fat (g)\n",
    "        fat = nutrition_dict.get('fat', None)\n",
    "        if fat is not None:\n",
    "            fat = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", fat)\n",
    "        fat_list.append(fat)\n",
    "\n",
    "        #Cholesterol (mg)\n",
    "        cholesterol = nutrition_dict.get('cholesterol', None)\n",
    "        if cholesterol is not None:\n",
    "            cholesterol = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", cholesterol)\n",
    "        cholesterol_list.append(cholesterol)\n",
    "\n",
    "        #Sodium (mg)\n",
    "        sodium = nutrition_dict.get('sodium', None)\n",
    "        if sodium is not None:\n",
    "            sodium = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", sodium)\n",
    "        sodium_list.append(sodium)\n",
    "\n",
    "        #calories\n",
    "        calorie = nutrition_dict.get('calories', None)\n",
    "        if calorie is not None:\n",
    "            calorie = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", calorie)\n",
    "        calorie_list.append(calorie)\n",
    "\n",
    "        #Recipe Number\n",
    "        recipe_id = str(i)\n",
    "        recipe_id_list.append(recipe_id)\n",
    "\n",
    "    except:\n",
    "        print(\"no recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = flatten(title_list)\n",
    "description_list = flatten(description_list)\n",
    "star_list = flatten(star_list)\n",
    "rating_list = flatten(rating_list)\n",
    "review_list = flatten(review_list)\n",
    "photo_list = flatten(photo_list)\n",
    "num_ingredient_list = flatten(num_ingredient_list)\n",
    "ingredient_list = flatten(ingredient_list)\n",
    "total_time_list = flatten(total_time_list)\n",
    "prep_time_list = flatten(prep_time_list)\n",
    "cook_time_list = flatten(cook_time_list)\n",
    "additional_time_list = flatten(additional_time_list)\n",
    "serving_list = flatten(serving_list)\n",
    "protein_list = flatten(protein_list)\n",
    "carb_list = flatten(carb_list)\n",
    "fat_list = flatten(fat_list)\n",
    "cholesterol_list = flatten(cholesterol_list)\n",
    "sodium_list = flatten(sodium_list)\n",
    "calorie_list = flatten(calorie_list)\n",
    "recipe_id_list = flatten(recipe_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame(list(zip(recipe_id_list, title_list, description_list,rating_list, review_list, photo_list, ingredient_list, num_ingredient_list,prep_time_list,\n",
    "                          cook_time_list, additional_time_list, total_time_list, serving_list,\n",
    "                          protein_list, carb_list, fat_list, cholesterol_list, sodium_list, calorie_list,star_list)),\n",
    "                 columns=['Recipe ID','Recipe', 'Description', 'Total Ratings', 'Total Reviews', 'Number of Photos',\n",
    "                          'Ingredients', 'Number of Ingredients',\n",
    "                          'Prep Time (mins)', 'Cook Time (mins)', 'Additional Time (mins)', 'Total Time (mins)',\n",
    "                          'Servings', 'Protein (g)', 'Carbs (g)', 'Fat (g)', 'Cholesterol (mg)',\n",
    "                          'Sodium (mg)','Calories', 'Rated Star'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input credentials through separate config file\n",
    "AWS_ACCESS_KEY_ID = 'x'\n",
    "AWS_SECRET_ACCESS_KEY = 'y'\n",
    "AWS_SESSION_TOKEN = os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "\n",
    "#saving csv file to s3 bucket location\n",
    "aws_credentials = { \"key\": AWS_ACCESS_KEY_ID, \"secret\": AWS_SECRET_ACCESS_KEY, \"token\": AWS_SESSION_TOKEN }\n",
    "df.to_csv(\"s3://<bucketname>/<path>/all_recipes_webscrapping.csv\", index=False, storage_options=aws_credentials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
